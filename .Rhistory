plot(bestsubset.fit, scale = "bic")
#getting coef of a set # of variables
coef(bestsubset.fit, which.min(bestsub.summary$cp))
###>>> best subset using forward and backwards method
#forward
fwd.fit = regsubsets(Attrition ~ . - EmployeeCount -EmployeeNumber - Over18 - StandardHours  ,
data = hr.attrit, method = "forward",nvmax = length(attrit.fit1), nbest = 1)
summary(fwd.fit)
plot(fwd.fit, scale = "Cp")
coef(fwd.fit, which.min(summary(fwd.fit)$cp))
#backward
bwd.fit = regsubsets(Attrition ~ . - EmployeeCount -EmployeeNumber - Over18 - StandardHours  ,
data = hr.attrit, method = "backward",nvmax = length(attrit.fit1), nbest = 1)
summary(bwd.fit)
plot(bwd.fit, scale = "Cp")
coef(bwd.fit, which.min(summary(bwd.fit)$cp))
# To obtain confidence intervals for the coefficient estimates
confint(attrit.fit1)
## odds ratios only
exp(coef(attrit.fit1))
##Writing my owen predict() funcion for regsubset()
predict.regsubsets = function(object,newdata,id,...){
form = as.formula(object$call[[2]]) # Extract the formula used when we called regsubsets()
mat = model.matrix(form,newdata)    # Build the model matrix
coefi = coef(object,id=id)          # Extract the coefficiants of the ith model
xvars = names(coefi)                # Pull out the names of the predictors used in the ith model
mat[,xvars]%*%coefi               # Make predictions using matrix multiplication
}
##Cross-Validation
k = 10                 # number of folds
set.seed(1)            # set the random seed so we all get the same results
# The perform best subset selection on the full dataset, minus the jth fold
best.fit = regsubsets(Attrition ~  Age + DistanceFromHome + EducationField
+ JobSatisfaction + Gender + JobInvolvement + JobRole + MaritalStatus
+ NumCompaniesWorked + OverTime + RelationshipSatisfaction + TotalWorkingYears
+ WorkLifeBalance + TrainingTimesLastYear + WorkLifeBalance + YearsAtCompany + YearsInCurrentRole
+ YearsSinceLastPromotion + YearsWithCurrManager,data = hr.attrit[folds!=j,], nvmax = 20)
#We see that cross-validation selects an 20-predictor model. Now let's use best subset
#selection on the full data set in order to obtain the 20-predictor model.
reg.best = regsubsets(Attrition ~ . - EmployeeCount -EmployeeNumber - Over18 - StandardHours,
data = hr.attrit, nvmax = 20 )
coef(reg.best, 20)
reg_summary = summary(reg.best)
#visulaiztion of CV results
par(mfrow=c(2,2))
# Plot RSS
plot(reg_summary$rss, xlab = "Number of Variables", ylab = "RSS", type = "l")
# Plot Adjusted R^2, highlight max value
plot(reg_summary$adjr2, xlab = "Number of Variables", ylab = "Adjusted RSq", type = "l")
max = which.max(reg_summary$adjr2)
points(max, reg_summary$adjr2[max], col = "red", cex = 2, pch = 20)
# Plot Cp, highlight min value
plot(reg_summary$cp, xlab = "Number of Variables", ylab = "Cp", type = "l")
min = which.min(reg_summary$cp)
points(min,reg_summary$cp[min], col = "red", cex = 2, pch = 20)
# Plot BIC, highlight min value
plot(reg_summary$bic, xlab = "Number of Variables", ylab = "BIC", type = "l")
min = which.min(reg_summary$bic)
points(min, reg_summary$bic[min], col = "red", cex = 2, pch = 20)
#produce diagnostic plots for logistic regression
##################    Improtant note before submitting  #################
### NEED to ad plot titles, and what ever else
par(mfrow = c(2,2))
plot(attrit.fit1)
#str(attrit.fit1)
#to get CI
#confint(attrit.fit1)
#to get standard CI
#confint.default(attrit.fit1)
## multicollinearity test
library(rockchalk)
mcDiagnose(attrit.fit1)
#https://github.com/rstudio/keras/issues/626
#https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset
#factor link
#https://www.dummies.com/programming/r/how-to-convert-a-factor-in-r/
# 2. using a loop
#for (i in 1 : ncol(hr.attrit)) {
#  print(names(hr.attrit[i]))
#  names = names(hr.attrit[i])
#  print(class(hr.attrit [,i]))
#}
# The perform best subset selection on the full dataset, minus the jth fold
best.fit = regsubsets(Attrition ~  Age + DistanceFromHome + EducationField
+ JobSatisfaction + Gender + JobInvolvement + JobRole + MaritalStatus
+ NumCompaniesWorked + OverTime + RelationshipSatisfaction + TotalWorkingYears
+ WorkLifeBalance + TrainingTimesLastYear + WorkLifeBalance + YearsAtCompany + YearsInCurrentRole
+ YearsSinceLastPromotion + YearsWithCurrManager,data = hr.attrit, nvmax = 20)
###>>> best subset using forward and backwards method
#forward
fwd.fit = regsubsets(Attrition ~ . - EmployeeCount -EmployeeNumber - Over18 - StandardHours  ,
data = hr.attrit, method = "forward",nvmax = length(attrit.fit1), nbest = 1)
fwdsub.summary = summary(fwd.fit)
names(fwd.sub)
fwd.summary = summary(fwd.fit)
names(fwd.summary)
plot(fwd.summary$rss, xlab = "Number of Variables", ylab = "RSS", type = "l")
plot (fwd.summary$adjr2, xlab = "Number of Variables", ylab = "Adjusted RSq", type = "l")
### NEED to ad plot titles, and what ever else
par(mfrow = c(1,1))
plot(attrit.fit1)
par(mfrow = c(2,2))
plot(attrit.fit1)
str(attrit.fit1)
## multicollinearity test
library(rockchalk)
mcDiagnose(attrit.fit1)
rm(list = ls())
library(DescTools)
library(arm)
library(car)
library(rockchalk)
library(visreg)
library(nonnest2)
### supress scientific notation
options(scipen=999)
## admission data set
dat <- read.csv("http://www.karlin.mff.cuni.cz/~pesta/prednasky/NMFM404/Data/binary.csv")
head(dat)
summary(dat)
dat$rank_factor <- as.factor(dat$rank)
summary(dat)
dat$rank_factor
## logistic regression
# Null model
#glm = generalized lm
mod_null <- glm(admit ~ 1, data = dat, family = binomial(link="logit"))
summary(mod_null)
coef(mod_null)  #cofficient
invlogit(coef(mod_null)) # proportion of admitted people in the sample
# GPA predictor
mod_gpa <- glm(admit ~ gpa, data = dat, family = binomial(link="logit"))
summary(mod_gpa)
exp(coef(mod_gpa)) ## OR    #odd ratio
invlogit(coef(mod_gpa)[1])
abs(exp(coef(mod_gpa))-1)*100 ## percentage change
PseudoR2(mod_gpa, "all")
visreg(mod_gpa, "gpa", scale="linear", xlab="GPA", ylab="Log-odds (admission)")
visreg(mod_gpa, "gpa", scale="response", xlab="GPA", ylab="P (admission)")
visreg(mod_gpa, "gpa", trans=exp, scale="linear", xlab="GPA", ylab="Odds Ratio (admission)")
## correctly classify / all possible subjects
(254+30)/(254+97+19+30) ## proportion of correctly classfiy with a 0.5 cutoff in the probability
library(DescTools)
library(arm)
library(car)
library(rockchalk)
library(visreg)
library(nonnest2)
### supress scientific notation
options(scipen=999)
## admission data set
dat <- read.csv("http://www.karlin.mff.cuni.cz/~pesta/prednasky/NMFM404/Data/binary.csv")
head(dat)
summary(dat)
## admit: was the student admitted to graduate school?
## gre: gre score
## gpa: undergraduate GPA
## rank: prestige rank for the university where they finished the undergraduate. 1 is higher rank
dat$rank_factor <- as.factor(dat$rank)
summary(dat)
dat$rank_factor
## logistic regression
# Null model
#glm = generalized lm
mod_null <- glm(admit ~ 1, data = dat, family = binomial(link="logit"))
summary(mod_null)
coef(mod_null)  #cofficient
invlogit(coef(mod_null)) # proportion of admitted people in the sample
# GPA predictor
mod_gpa <- glm(admit ~ gpa, data = dat, family = binomial(link="logit"))
summary(mod_gpa)
exp(coef(mod_gpa)) ## OR    #odd ratio
invlogit(coef(mod_gpa)[1])
abs(exp(coef(mod_gpa))-1)*100 ## percentage change
PseudoR2(mod_gpa, "all")
visreg(mod_gpa, "gpa", scale="linear", xlab="GPA", ylab="Log-odds (admission)")
visreg(mod_gpa, "gpa", scale="response", xlab="GPA", ylab="P (admission)")
visreg(mod_gpa, "gpa", trans=exp, scale="linear", xlab="GPA", ylab="Odds Ratio (admission)")
## correctly classify / all possible subjects
(254+30)/(254+97+19+30) ## proportion of correctly classfiy with a 0.5 cutoff in the probability
## multicollinearity test
mcDiagnose(mod1)
## compare models
## is GRE and GPA needed
mod0 <- glm(admit ~ rank_factor, data = dat, family = binomial(link="logit"))
summary(mod0)
## compare models, can compare addition/substraction of multiple predictors
## Likelihood Ratio model comparison
anova(mod0, mod1)
1-pchisq(16.449, df=2)
vuongtest(mod0, mod1, nested=T) ## Vuong test, robust LRT/chi-square. From nonnest2
## compare adition of each predictor: from car
## Basic ANOVA table
Anova(mod1, type=2, test.statistic="LR")
# Rank of university as predictor (categorical)
mod_rank <- glm(admit ~ rank_factor, data = dat, family = binomial(link="logit"))
summary(mod_rank)
anova(mod_rank)
Anova(mod_rank, test="LR")
exp(coef(mod_rank)) ## OR
PseudoR2(mod_rank, "all")
CC <- coef(mod_rank)
CC
invlogit(CC[1])# probability of being admitted from rank 1
invlogit(CC[1] + 1*CC[2])# probability of being admitted from rank 2
invlogit(CC[1] + 1*CC[3])# probability of being admitted from rank 3
invlogit(CC[1] + 1*CC[4])# probability of being admitted from rank 4
visreg(mod_rank, "rank_factor", scale="linear", xlab="University Rank", ylab="Log-odds (admission)")
visreg(mod_rank, "rank_factor", scale="response", xlab="University Rank", ylab="P (admission)")
# continuous and categorical predictors
mod1 <- glm(admit ~ gre + gpa + rank_factor, data = dat, family = binomial(link="logit"))
summary(mod1)
exp(coef(mod1)) ## OR
abs(exp(coef(mod1))-1)*100 ## percentage change
confint(mod1, level = .95) ## CI for log-odds
exp(confint(mod1, level = .95)) ## CI for OR
PseudoR2(mod1, "all")
visreg(mod1, "rank_factor", scale="response", xlab="University Rank", ylab="P (admission)")
visreg(mod1, "gpa", scale="response", xlab="GPA", ylab="P (admission)")
## put all results in 1 table
res <- cbind(summary(mod1)$coefficients[,c("Estimate","Std. Error","Pr(>|z|)")],
OR=exp(coef(mod1)),
exp(confint(mod1, level = .95)))
res
round(res, 3)
invlogit(coef(mod1)[1])
### accuracy of classification
logreg2prob <- invlogit(predict(mod1))
table(logreg2prob >= 0.5, dat$admit)
invlogit(coef(mod1)[1])
### accuracy of classification
logreg2prob <- invlogit(predict(mod1))
table(logreg2prob >= 0.5, dat$admit)
## correctly classify / all possible subjects
(254+30)/(254+97+19+30) ## proportion of correctly classfiy with a 0.5 cutoff in the probability
## multicollinearity test
mcDiagnose(mod1)
## compare models
## is GRE and GPA needed
mod0 <- glm(admit ~ rank_factor, data = dat, family = binomial(link="logit"))
summary(mod0)
## compare models, can compare addition/substraction of multiple predictors
## Likelihood Ratio model comparison
anova(mod0, mod1)
1-pchisq(16.449, df=2)
vuongtest(mod0, mod1, nested=T) ## Vuong test, robust LRT/chi-square. From nonnest2
## compare adition of each predictor: from car
## Basic ANOVA table
Anova(mod1, type=2, test.statistic="LR")
### center predictors
dat$grec <- scale(dat$gre, center = T, scale = F)
dat$gpac <- scale(dat$gpa, center = T, scale = F)
### standardize predictors
dat$grez <- scale(dat$gre, center = T, scale = T)
dat$gpaz <- scale(dat$gpa, center = T, scale = T)
summary(dat)
## logistic with center predictors
mod1c <- glm(admit ~ grec + gpac, data = dat, family = binomial(link="logit"))
summary(mod1c)
PseudoR2(mod1c, "all")
exp(coef(mod1c))
invlogit(coef(mod1c)[1])
## multicollinearity test
mcDiagnose(mod1c)
## center results
resc <- cbind(summary(mod1c)$coefficients[,c("Estimate","Std. Error","Pr(>|z|)")],
OR=exp(coef(mod1c)),
exp(confint(mod1c, level = .95)))
resc
round(resc, 3)
## logistic with standardize predictors
mod1z <- glm(admit ~ grez + gpaz, data = dat, family = binomial(link="logit"))
summary(mod1z)
PseudoR2(mod1z, "all")
exp(coef(mod1z))
abs(exp(coef(mod1z))-1)*100 ## percentage change
invlogit(coef(mod1z)[1])
## multicollinearity test
mcDiagnose(mod1z)
## standardize results
resz <- cbind(summary(mod1z)$coefficients[,c("Estimate","Std. Error","Pr(>|z|)")],
OR=exp(coef(mod1z)),
exp(confint(mod1z, level = .95)))
resz
round(resz, 3)
#### compare slopes from different predictors
#### both predictors must be in the same metric, lets say standardize
linearHypothesis(mod1z, "grez=gpaz")
## interpretation of intercept
## results from a model with an interpretable intercept
## no weird 0 values for predictors
## for example with standardize predictors
summary(dat)
resz
resz[1,1]
invlogit(resz[1,1])
## probability of being admitted with average gpa (3.39) and gre (587.7)
##### plot logistic
## Use the inverse logit to transform predicted log(odds) into probabilities
res
summary(mod1)
predict(mod1) ## predicted log(odds) for each subject
pred_probs <- invlogit(predict(mod1)) ## predicted probability of being accepted for every subject
par(mfrow=c(1,3))
plot(dat$gpa, pred_probs)
plot(dat$gre, pred_probs)
plot(dat$rank_factor, pred_probs)
par(mfrow=c(1,1))
## plot conditional eff
# need a continuous escores of GRE
gres <- seq(from=min(dat$gre), to=max(dat$gre), by=.5)
CC <- coef(mod1)
CC
probs_rank1_gre <- invlogit(CC[1]+ # intercept
CC[2]*gres+ # all possible values of GRE
CC[3]*3+ ## GPA = 3
CC[4]*0+ # rank 2 =0
CC[5]*0+ # rank 3 =0
CC[6]*0) # rank 4 =0
probs_rank2_gre <- invlogit(CC[1]+ # intercept
CC[2]*gres+ # all possible values of GRE
CC[3]*3+ ## GPA = 3
CC[4]*1+ # rank 2 =1
CC[5]*0+ # rank 3 =0
CC[6]*0) # rank 4 =0
probs_rank3_gre <- invlogit(CC[1]+ # intercept
CC[2]*gres+ # all possible values of GRE
CC[3]*3+ ## GPA = 3
CC[4]*0+ # rank 2 =0
CC[5]*1+ # rank 3 =1
CC[6]*0) # rank 4 =0
probs_rank4_gre <- invlogit(CC[1]+ # intercept
CC[2]*gres+ # all possible values of GRE
CC[3]*3+ ## GPA = 3
CC[4]*0+ # rank 2 =0
CC[5]*0+ # rank 3 =0
CC[6]*1) # rank 4 =1
plot(gres, probs_rank1_gre, xlab = "GRE", ylab = "Probability of admission",
ylim = c(0,1))
points(gres, probs_rank2_gre, col="red")
points(gres, probs_rank3_gre, col="blue")
points(gres, probs_rank4_gre, col="green")
legend("topleft",pch = 1, col=c("black","red","blue","green"),
legend = c("Rank 1","Rank 2", "Rank 3", "Rank 4"))
gpas <- seq(from=min(dat$gpa), to=max(dat$gpa), by=.008)
CC <- coef(mod1)
CC
probs_rank1_gpa <- invlogit(CC[1]+ # intercept
CC[2]*700+ # GRE = 700
CC[3]*gpas+ # all possible values of GPA
CC[4]*0+ # rank 2 =0
CC[5]*0+ # rank 3 =0
CC[6]*0) # rank 4 =0
probs_rank2_gpa <- invlogit(CC[1]+ # intercept
CC[2]*700+ # GRE = 700
CC[3]*gpas+ # all possible values of GPA
CC[4]*1+ # rank 2 =1
CC[5]*0+ # rank 3 =0
CC[6]*0) # rank 4 =0
probs_rank3_gpa <- invlogit(CC[1]+ # intercept
CC[2]*700+ # GRE = 700
CC[3]*gpas+ # all possible values of GPA
CC[4]*0+ # rank 2 =0
CC[5]*1+ # rank 3 =1
CC[6]*0) # rank 4 =0
probs_rank4_gpa <- invlogit(CC[1]+ # intercept
CC[2]*700+ # GRE = 700
CC[3]*gpas+ # all possible values of GPA
CC[4]*0+ # rank 2 =0
CC[5]*0+ # rank 3 =0
CC[6]*1) # rank 4 =1
plot(gpas, probs_rank1_gpa, xlab = "GPA", ylab = "Probability of admission",
ylim = c(0,1))
points(gpas, probs_rank2_gpa, col="red")
points(gpas, probs_rank3_gpa, col="blue")
points(gpas, probs_rank4_gpa, col="green")
legend("topleft",pch = 1, col=c("black","red","blue","green"),
legend = c("Rank 1","Rank 2", "Rank 3", "Rank 4"))
#### lets put them together
par(mfrow=c(1,2))
plot(gres, probs_rank1_gre, xlab = "GRE", ylab = "Probability of admission",
ylim = c(0,1))
points(gres, probs_rank2_gre, col="red")
points(gres, probs_rank3_gre, col="blue")
points(gres, probs_rank4_gre, col="green")
legend("topleft",pch = 1, col=c("black","red","blue","green"),
legend = c("Rank 1","Rank 2", "Rank 3", "Rank 4"))
plot(gpas, probs_rank1_gpa, xlab = "GPA", ylab = "Probability of admission",
ylim = c(0,1))
points(gpas, probs_rank2_gpa, col="red")
points(gpas, probs_rank3_gpa, col="blue")
points(gpas, probs_rank4_gpa, col="green")
legend("topleft",pch = 1, col=c("black","red","blue","green"),
legend = c("Rank 1","Rank 2", "Rank 3", "Rank 4"))
par(mfrow=c(1,1))
CC
invlogit(CC[1]+
CC[2]*750+
CC[3]*3.8+
CC[4]*0+
CC[5]*0+
CC[6]*0)
## plots with visreg
summary(mod1)
visreg(mod1, "gpa", scale="response", xlab="GPA", ylab="P (admission)")
## for probability of being admitted
visreg(mod1, "gpa", by="rank_factor", scale="response", xlab="GPA", ylab="P (admission)")
visreg(mod1, "gpa", by="rank_factor", overlay=T, scale="response", xlab="GPA", ylab="P (admission)")
## for log-odds of being admitted
visreg(mod1, "gpa", by="rank_factor", scale="linear", xlab="GPA", ylab="Log-odds (admission)")
visreg(mod1, "gpa", by="rank_factor", overlay=T, scale="linear", xlab="GPA", ylab="Log-odds (admission)")
## for Odds Ratio of being admitted
visreg(mod1, "gpa", by="rank_factor", trans=exp, scale="linear", xlab="GPA", ylab="Odds Ratio (admission)")
visreg(mod1, "gpa", by="rank_factor", trans=exp, overlay=T, scale="linear", xlab="GPA", ylab="Odds Ratio (admission)")
##predictation
attrit.probs = predict(best.fit, type = 'response')
library(boot)
##Cross-Validation
k = 10                 # number of folds
set.seed(17)            # set the random seed so we all get the same results
cv.error = rep(0,20)
for(i in 1:20) {
# The perform best subset selection on the full dataset, minus the jth fold
best.fit = regsubsets(Attrition ~  Age + DistanceFromHome + EducationField
+ JobSatisfaction + Gender + JobInvolvement + JobRole + MaritalStatus
+ NumCompaniesWorked + OverTime + RelationshipSatisfaction + TotalWorkingYears
+ WorkLifeBalance + TrainingTimesLastYear + WorkLifeBalance + YearsAtCompany + YearsInCurrentRole
+ YearsSinceLastPromotion + YearsWithCurrManager,data = hr.attrit, nvmax = 20)
cv.error[i] = cv.glm (hr.attrit, best.fit, k = k)$delta[1]
}
cv.error
hr.attrit <- read.csv("HR_Employee_Attrition_NMDSI_data .csv", header = T)
hr.attrit = data.frame(hr.attrit)
summary(hr.attrit)
dim(hr.attrit)
colnames(hr.attrit)
#to find the type of data we're dealing with
# 1.usind one command
lapply(hr.attrit, class)
#sapply(hr.attrit, sd) # apply sd function to each variable in the dataset.
##################    Improtant note before submitting  #################
### NEED to add plot title, change color, prectange, etc
ggplot(data = hr.attrit, aes(x = Attrition)) + geom_bar(stat = "count")
ggplot(data = hr.attrit, aes(x = Attrition)) + geom_bar(stat = "count",
fill = "blue3", color = "grey40") + theme_bw() + coord_flip()
#the distribution of the attrition --- we have imbalanced data
##getting the frequency  of each variable
freq.hr = NULL
for ( i in 1 : ncol(hr.attrit)) {
freq.hr [[i]] <- table (hr.attrit [, i], useNA = "always")
}
names(freq.hr) <- colnames(hr.attrit)
#freq.hr
#decalring categorical variables as factor and numerical variables
#as.numeric(levels(f))[f]
hr.attrit$Attrition = factor(hr.attrit$Attrition, levels = c ('Yes', 'No') , labels = c(1, 2) )
hr.attrit$BusinessTravel = as.factor(as.integer(hr.attrit$BusinessTravel))
hr.attrit$Department = factor(as.integer(hr.attrit$Department))
hr.attrit$EducationField = factor(hr.attrit$EducationField,
levels = c('Human Resources', 'Life Sciences', 'Marketing', 'Medical', 'Technical Degree', 'Other'),
labels = c(1,2,3,4,5,6))
hr.attrit$Gender = factor(hr.attrit$Gender,
levels = c('Female', 'Male'),
labels = c(1,2))
hr.attrit$JobRole = factor(hr.attrit$JobRole,
levels = c('Healthcare Representative', 'Human Resources', 'Laboratory Technician', 'Manager', 'Manufacturing Director',
'Research Director', 'Research Scientist', 'Sales Executive', 'Sales Representative') ,
labels = c(1,2,3,4,5,6,7,8,9))
hr.attrit$MaritalStatus = factor(hr.attrit$MaritalStatus,levels = c('Single', 'Married', 'Divorced'),labels = c(1,2,3))
hr.attrit$OverTime = factor(hr.attrit$OverTime,levels = c('Yes','No'),labels = c(1,2))
hr.attrit$Over18 = as.numeric(hr.attrit$Over18, levels = c('Yes', 'No'),labels = c(1,2))
#full logistic model of all varibles
attrit.fit1 = glm( Attrition ~ . - EmployeeCount -EmployeeNumber - Over18 - StandardHours  , data = hr.attrit,
family = "binomial")
summary(attrit.fit1)
#to get the number of parameters in the fitted model.
length(coef(attrit.fit1))
# To obtain confidence intervals for the coefficient estimates
confint(attrit.fit1)
#to get standard CI
confint.default(attrit.fit1)
## odds ratios only
exp(coef(attrit.fit1))
## multicollinearity test
mcDiagnose(attrit.fit1)
###########Best Subset S
##Cross-Validation
k = 10                 # number of folds
set.seed(17)            # set the random seed so we all get the same results
cv.error = rep(0,20)
for(i in 1:20) {
# The perform best subset selection on the full dataset, minus the jth fold
best.fit = regsubsets(Attrition ~  Age + DistanceFromHome + EducationField
+ JobSatisfaction + Gender + JobInvolvement + JobRole + MaritalStatus
+ NumCompaniesWorked + OverTime + RelationshipSatisfaction + TotalWorkingYears
+ WorkLifeBalance + TrainingTimesLastYear + WorkLifeBalance + YearsAtCompany + YearsInCurrentRole
+ YearsSinceLastPromotion + YearsWithCurrManager,data = hr.attrit, nvmax = 20)
cv.error[i] = cv.glm (hr.attrit, best.fit, k = k)$delta[1]
}
cv.error
set.seed(17)            # set the random seed so we all get the same results
cv.error = rep(0,20)
for(i in 1:20) {
# The perform best subset selection on the full dataset, minus the jth fold
best.fit = regsubsets(Attrition ~  Age + DistanceFromHome + EducationField
+ JobSatisfaction + Gender + JobInvolvement + JobRole + MaritalStatus
+ NumCompaniesWorked + OverTime + RelationshipSatisfaction + TotalWorkingYears
+ WorkLifeBalance + TrainingTimesLastYear + WorkLifeBalance + YearsAtCompany + YearsInCurrentRole
+ YearsSinceLastPromotion + YearsWithCurrManager,data = hr.attrit, nvmax = 20)
cv.error[i] = cv.glm (hr.attrit, best.fit, k = 10)$delta[1]
}
cv.error
